# -*- coding: utf-8 -*-
"""Submission 3 TF-Lite.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iLSEhcIIXajkbvJAsI4MpQOYuu_Eh5yf
"""

import os
import tensorflow as tf
import matplotlib.pyplot as plt
from keras.callbacks import ReduceLROnPlateau
from PIL import Image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications import VGG19
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications import DenseNet201
from tensorflow.keras.applications import DenseNet121
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout

folder_images = "/content/drive/My Drive/animal_dataset/sheep"
size_images = dict()

for dirpath, _, filenames in os.walk(folder_images):
    
    for path_image in filenames:
        image = os.path.abspath(os.path.join(dirpath, path_image))
        with Image.open(image) as img:
            width, heigth = img.size
            size_images[path_image] = {'width': width, 'heigth': heigth}

print('resolusi pada dataset :\n',size_images)

train_dir = '/content/drive/My Drive/animal_dataset'
train_datagen = ImageDataGenerator(rescale=1/255,
                                   rotation_range=40,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   validation_split=0.2) # set validation split)

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150),
        batch_size=32,
        class_mode='categorical',
        subset='training')

validation_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150),
        batch_size=32, 
        class_mode='categorical',
        subset='validation')

total_train=len(train_generator)
total_val=len(validation_generator)

print("Total training data batches : ", total_train)
print("Total validation data batches: ", total_val)

densenet = DenseNet201(weights='imagenet',
                  include_top=False,input_shape=(150,150,3))


model = tf.keras.Sequential([
    densenet,
    tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Dense(4, activation='softmax')
])

model.summary()

import tensorflow as tf
opt = tf.keras.optimizers.SGD(lr=1e-4,momentum=0.99)
opt1 = tf.keras.optimizers.Adam(lr=2e-4)
opt2 = tf.keras.optimizers.RMSprop(momentum=0.99)
opt3 = tf.keras.optimizers.Adam(beta_1=0.9, beta_2=0.999, amsgrad=False)

model.compile(optimizer=opt3,
              loss = 'categorical_crossentropy',
              metrics=['accuracy'])

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.92)&(logs.get('val_accuracy')>0.92):
      print("\nAkurasi dan val_accuracy telah mencapai >92%!")
      self.model.stop_training = True
stop_train = myCallback()

lr_reduction = ReduceLROnPlateau(monitor='val_accuracy',
                                            patience=2,
                                            verbose=1,
                                            factor=0.5,
                                            min_lr=0.000003)

history = model.fit(train_generator,
                    steps_per_epoch=train_generator.n//train_generator.batch_size, 
                    validation_data=validation_generator,
                    validation_steps=validation_generator.n//validation_generator.batch_size,
                    epochs=50,
                    callbacks=[stop_train,lr_reduction])

# Konversi model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()


# -*- coding: utf-8 -*-
"""Salinan dari Submission 1 NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aSDlfIDYIBZkD7c9Ia-KabwxD6ZvPJ0Q
"""

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/Dataset/bbc-text.csv')
df

kategori = pd.get_dummies(df.category)
df_new = pd.concat([df, kategori], axis=1)
df_new = df_new.drop(columns='category')
max_len =  df_new['text'].map(lambda x: len(x.split())).max()
print(df_new)
print(max_len)

import re
#from nltk.download import stopwords
import nltk
#nltk.download('stopwords')
from nltk.corpus import stopwords

space = re.compile('[/(){}\[\]\|@,;]')
symbols= re.compile('[^0-9a-z #+_]')
STOPWORDS = set(stopwords.words('english'))

def text_cleaning(teks):
    teks = teks.lower()
    teks = space.sub(' ', teks)
    teks = symbols.sub('', teks)
    teks = teks.replace('x', '')
    teks = ' '.join(word for word in teks.split() if word not in STOPWORDS)
    return teks
df_new['text']=df_new['text'].apply(text_cleaning)

max_word = df_new['text']
max_sentence = max_word.map(lambda x: len(x.split())).max()
desc = df_new['text'].values
label = df_new[['business',	'entertainment', 'politics', 'sport',	'tech']].values
print(desc)
print(label)
print(max_sentence)

from sklearn.model_selection import train_test_split
desc_train, desc_test, label_train, label_test = train_test_split(desc, label, test_size=0.2)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
     
tokenizer = Tokenizer(num_words=40000, oov_token='x')
tokenizer.fit_on_texts(desc_train) 
tokenizer.fit_on_texts(desc_test)
     
seq_train = tokenizer.texts_to_sequences(desc_train)
seq_test = tokenizer.texts_to_sequences(desc_test)
     
pad_train = pad_sequences(seq_train, maxlen=max_sentence) 
pad_test = pad_sequences(seq_test, maxlen=max_sentence)

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=40000, output_dim=150, input_length=max_sentence),
    tf.keras.layers.SpatialDropout1D(0.25),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(5, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='RMSProp',metrics=['accuracy'])
model.summary()

num_epochs = 4
history = model.fit(pad_train, label_train, epochs=num_epochs,
                    validation_data=(pad_test, label_test), verbose=2)

